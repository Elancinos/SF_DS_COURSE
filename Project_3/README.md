# <center> ***Project_3 - Построение модели предсказания пользовательской оценки отелю***
---

## <center> <a id ="table_of_content">Оглавление</a>  
[1. Описание проекта](#description)  
[2. Знакомство с данными и подготовка к работе](#preparation)  
[3. Очистка данных](#data_cleaning)
[4. Анализ и подготовка данных](#data_preparation)  
[5. Отбор признаков](#data_picking)
[6. Обучение модели](#learning)  
[7. Вывод](#result)  
[8. Загрузка работы на соревнование Kaggle](#kaggle)  
[9. Итоги](#final)

---

### <center> <a id='description'> Описание проекта</a>

Наша задача в этом проекте - создать модель, основанную на алгоритмах машинного обучения, для предсказания рейтинга отели, исходя из данных представленного дата-сета. Для этого мы предварительно максимально обработаем его - очистим пропущенные значения, отберём необходимые признаки и создадим дополнительные, некоторые из них закодируем. После этого обучим нашу модель и подведём итог. Далее, нам нужно загрузить работу на [Kaggle](https://www.kaggle.com/) и удостовериться, что всё работает.

Итак, работа состоит из нескольких этапов:

* Знакомство с данными и подготовка к работе;
* Очистка данных;
* Анализ и подготвока данных;
* Отбор признаков;
* Обучение модели;
* Вывод;
* Загрузка работы на соревнование Kaggle.

Подробнее о каждом этапе в можно узнать в соответствующих пунктах, тыкнув на интересующий в оглавлении, или просто промотав.

#### :question: ***Зачем нужна данная работа?***
Данная работа нужна для отработки навыков предварительной обработки данныхъ для моделей машинного обучения и знакомства с последними на практике. А также для практического ознакомления с платформой Kaggle.

#### :exclamation: ***Пару слов о процессе выполнения***
В процессе выполения работы старался комментировать интересные места и особенности, а также проводить дополнительные исследования при необходимости, отходя от заданий, где считал это необходимым. Всё для более качественного выполнения общего задания каждой части работы.
Также в работе есть несколько закомментированных полей с кодом, которые вызывают ошибки/баги с данными. Обработка данных велась с целью максимального уменьшения количества ошибок, потому есть такие поля.
Также есть строки, которые являются опциональными. Их можно раскоментировать, ошибок и багов не случится (вроде), но результат может отличаться от моего, в чаще всего в худшую сторону.

Версии и информацию об использованных в работе библиотеках можно найти в файле "pyproject.toml", полный набор пакетов - в файле "poetry.lock". Соответсвенно, в качестве менеджера версий использовался poetry.

:floppy_disk: Исходные файлы датасетов из работы для удобства сохранил по ссылке (Гугл диск): https://drive.google.com/file/d/1kSaZraaGI5FZj8ECXBK4_W568i3urVqB/view?usp=drive_link

:floppy_disk: Получившийся ноутбук на Kaggle: https://www.kaggle.com/code/elancinos/project-3-kaggle-version-v2

Также в репозитории в папке "graphs" можно найти получившиеся графики библиотеки plotly в формате html.

---

### <center> <a id='preparation'> Знакомство с данными и подготовка к работе </a>

На этом этапе рассказывается о столбцах дата-сета и подгружаются все необходимые для работы библиотеки и сам дата-сет.

:arrow_up: [к оглавлению](#table_of_content) :arrow_up:

---

### <center> <a id='data_cleaning'> Очистка данных </a>

Короткий этап выявления и очистки данных от строк-дубликатов. Пропущенных строк тут нет, потому ограничиваемся этим.

:arrow_up: [к оглавлению](#table_of_content) :arrow_up:

---

### <center> <a id='data_preparation'> Анализ и подготовка данных </a>

Этап, на котором мы визуализируем данные, выделяем из существующих признаков дополнительные и преобразуем их в понятные для алгоритма машинного обучения форматы данных, чаще всего кодируем.

:arrow_up: [к оглавлению](#table_of_content) :arrow_up:

---

### <center> <a id='data_picking'> Очистка данных </a>

На этом этапе мы строим тепловые карты корреляций признаков и графики значимости. Таким образом отсекаются малозначимые (засоряющие) признаки и те, информация в которых очень похожа на содержащуюся в каком-то другом признаке. Такие признаки не дубликаты, но близки к ним.

На этапе загрузки и тестирования на платформе Kaggle было принято реение данный этап пропустить - вернее, не вносить результаты по данному этапу в данные, так как результат с ним отличался от эталонного в худшую сторону.

:arrow_up: [к оглавлению](#table_of_content) :arrow_up:

---

### <center> <a id='learning'> Обучение модели </a>

На этом этапе происходим обучение модели, в результате на выходе мы видим MAPE - средняя вероятность абсолютной ошибки.

:arrow_up: [к оглавлению](#table_of_content) :arrow_up:

---

### <center> <a id='result'> Вывод </a>

На этапе делается небольшой промежуточный вывод о работе (В локальном ноутбуке).

:arrow_up: [к оглавлению](#table_of_content) :arrow_up:

---

### <center> <a id='kaggle'>  Загрузка работы на соревнование Kaggle </a>

На этом этапе мы загружаем получившийся ноутбук в соревнование на платформе Kaggle и пытаемся подружить его с платформой для получения тех же результатов MAPE, которые были в локальном ноутбуке.

Пару слов о процессе - результат на платформе немного отличается от полученного в локальном ноутбуке. Также немного отличается принцип загрузки данных, а также есть этап проверки обученной модели и сверки результатов с эталоном. По итогу результат на платформе - 12,595%.

Также стоит отметить, что на платформе этап отбора признаков приводит к ухудшению результата. Потому, там я его исключил. Вернее, закомментировал, при желании можно разкомментировать и посмотреть разницу.

:floppy_disk: Ещё раз продублирую ссылку на ноутбук на платформе: https://www.kaggle.com/code/elancinos/project-3-kaggle-version-v2.

:arrow_up: [к оглавлению](#table_of_content) :arrow_up:

---

### <center> <a id='final'> Итоги </a>

Подведение итогов по работе.

Всё запланированное к выполнению выполнено, обработаны данные, получена модель, MAPE, а также адаптирован и загружен ноутбук на платформу Kaggle. При этом были отобраны оптимальные связки признаков опытным путём - всё для улучшения предсказания. При этом результаты немного отличаются - на платформе они лучше. При этом после сверки с эталоном результат немного хуже - 12,503% против 12,595%. Минимально получившийся MAPE на платформе - ~12,48%, при этом страдал результат после сверки - ~12,605%. Потому было принято решение пропустить этап отбора признаков, так результат после сверки максимально близкий к эталону.

:arrow_up: [к оглавлению](#table_of_content) :arrow_up: