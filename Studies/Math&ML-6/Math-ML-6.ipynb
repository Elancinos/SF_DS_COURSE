{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617eeeab",
   "metadata": {},
   "source": [
    "# <center> MATH&ML-6. Математический анализ в контексте задачи оптимизации. Часть III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d03f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорты\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy\n",
    "from sympy import Eq, solveset, Symbol, symbols, Interval, S, log, sin, cos, exp, diff, solve, N\n",
    "# Аккуратный вывод формул\n",
    "from sympy import init_printing\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sympy.calculus.util import function_range, continuous_domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698ebd8",
   "metadata": {},
   "source": [
    "### Юнит 1. Введение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5f6245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 4 x^{3} + 18 x^{2} - 8 x$"
      ],
      "text/plain": [
       "-4*x**3 + 18*x**2 - 8*x"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1/2, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ: 144\n"
     ]
    }
   ],
   "source": [
    "# Задание 1.1\n",
    "\n",
    "x, w = symbols('x w')\n",
    "func = -x**4 + 6*x**3 - 4*x**2 + 80\n",
    "display(func.diff(x))\n",
    "display(solve(func.diff(x)))\n",
    "\n",
    "print('Ответ:',-4**4 + 6*4**3 - 4*4**2 + 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9202741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diff x: w + 2*x'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'diff y: w + 4*y'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'diff w: x + y - 20'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{w: -80/3, x: 40/3, y: 20/3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ответ: 800'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Задание 1.4\n",
    "x, y, w = symbols('x y w')\n",
    "func = x**2 + 2*y**2\n",
    "g = x + y - 20\n",
    "\n",
    "full_func = func + w*g\n",
    "display(f'diff x: {full_func.diff(x)}')\n",
    "display(f'diff y: {full_func.diff(y)}')\n",
    "display(f'diff w: {full_func.diff(w)}')\n",
    "xyw = solve([full_func.diff(x), full_func.diff(y), full_func.diff(w)], x, y, w)\n",
    "display(xyw)\n",
    "display(f'Ответ: {(xyw[x]**2 + 2*xyw[y]**2)*3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da3540",
   "metadata": {},
   "source": [
    "### Юнит 2. Градиентный спуск: применение и модификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87ed2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26.8 s\n",
      "Wall time: 37.6 s\n",
      "accuracy на тестовом наборе: 0.957\n",
      "MSE на тестовом наборе: 0.044\n",
      "Наилучшие значения гиперпараметров: {'alpha': np.float64(0.001), 'eta0': np.float64(0.001), 'l1_ratio': np.float64(0.0), 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "# Задание 2.7\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import metrics\n",
    "df = sns.load_dataset('diamonds')\n",
    "# display(df)\n",
    "\n",
    "df.drop(['depth', 'table', 'x', 'y', 'z'], axis=1, inplace=True)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df['carat'] = np.log(1+df['carat'])\n",
    "df['price'] = np.log(1+df['price'])\n",
    "\n",
    "X = df.drop(columns=\"price\")\n",
    "y = df[\"price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "    \"loss\": [\"squared_error\", \"epsilon_insensitive\"],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"alpha\": np.logspace(-3, 3, 10),\n",
    "    \"l1_ratio\": np.linspace(0, 1, 10),\n",
    "    \"learning_rate\": [\"constant\"],\n",
    "    \"eta0\": np.logspace(-4, -1, 4)\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=SGDRegressor(\n",
    "        random_state=42,\n",
    "        max_iter=1200\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time grid_search.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.3f}\".format(grid_search.score(X_test, y_test)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('MSE на тестовом наборе: {:.3f}'.format(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d1b79",
   "metadata": {},
   "source": [
    "### Юнит 3. Метод Ньютона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42483018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 30 x^{4} - 20 x^{3} - 12 x^{2} + 6 x$"
      ],
      "text/plain": [
       "30*x**4 - 20*x**3 - 12*x**2 + 6*x"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.630 0.629 0.628\n",
      "Iter 1: x = 0.7094, f(x) = -0.1066, grad = -0.0941\n",
      "Iter 2: x = 0.7201, f(x) = -0.1206, grad = -0.1066\n",
      "Iter 3: x = 0.7321, f(x) = -0.1361, grad = -0.1206\n",
      "Iter 4: x = 0.7457, f(x) = -0.1531, grad = -0.1361\n",
      "Iter 5: x = 0.7611, f(x) = -0.1711, grad = -0.1531\n"
     ]
    }
   ],
   "source": [
    "# Задание 3.1\n",
    "\n",
    "x = symbols('x')\n",
    "func = 6*x**5 - 5*x**4 - 4*x**3 + 3*x**2\n",
    "display(func.diff())\n",
    "x0 = 0.7\n",
    "x1 = N(x0 - (func.subs(x, x0).evalf())/(func.diff().subs(x, x0)), 3)\n",
    "x2 = N(x1 - (func.subs(x, x1).evalf())/(func.diff().subs(x, x1)), 3) # Нужный\n",
    "x3 = N(x2 - (func.subs(x, x2).evalf())/(func.diff().subs(x, x2)), 3)\n",
    "\n",
    "print(x0, x1, x2, x3)\n",
    "\n",
    "#Автоматическое решение Deepseek (По сути реализация градиентного спуска, для этого задания не подходит, он не понял, что от него хотят)\n",
    "learning_rate = 0.1\n",
    "current_x = 0.7  # Начальная точка\n",
    "n_iterations = 5\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    grad = func.subs(x, current_x).evalf()  # Вычисляем градиент в текущей точке\n",
    "    current_x = current_x - learning_rate * grad  # Обновляем x (градиентный спуск)\n",
    "    current_f = func.subs(x, current_x).evalf()      # Значение функции в новой точке\n",
    "    print(f\"Iter {i+1}: x = {current_x:.4f}, f(x) = {current_f:.4f}, grad = {grad:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e66d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.695121951219512\n",
      "11.734125501243229\n",
      "7.1123493600499685\n",
      "5.365000391507974\n",
      "5.015260627016227\n",
      "5.000029000201801\n",
      "5.000000000105126\n",
      "5.000000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.000000000000001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(5.000000000105126)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "func0 = x**3 - 3*x**2 - 45*x - 40\n",
    "\n",
    "def func1(x):\n",
    "    return 3*x**2 - 6*x -45\n",
    "def func2(x):\n",
    "    return 6*x - 6\n",
    "\n",
    "#Ручной цикл\n",
    "initial_value = 42\n",
    "iter_count = 0\n",
    "x_curr = initial_value\n",
    "epsilon = 0.0001\n",
    "f = func1(x_curr)\n",
    "\n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)\n",
    "    \n",
    "# Через функцию\n",
    "def newtons_method(f, fprime, x0, tol=0.0001):\n",
    "    iter_count = 0\n",
    "    x_curr = x0\n",
    "    f_val = f(x_curr)\n",
    "    while (abs(f_val) > tol):\n",
    "        f_val = f(x_curr)\n",
    "        f_prime_val = fprime(x_curr)\n",
    "        x_curr = x_curr - (f_val)/(f_prime_val)\n",
    "        iter_count += 1\n",
    "    return x_curr\n",
    "\n",
    "display(newtons_method(f=func1, fprime=func2, x0=42, tol=0.0001))\n",
    "\n",
    "from scipy.optimize import newton\n",
    "display(newton(func=func1, fprime=func2, x0=42, tol=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e1203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 919/90 9.756 9.727 9.727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(9.727)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задание 3.6\n",
    "func = x**3 - 72*x - 220\n",
    "x0 = 12\n",
    "\n",
    "x = symbols('x')\n",
    "x1 = x0 - (func.subs(x, x0)/func.diff().subs(x, x0))\n",
    "x2 = x1 - (func.subs(x, x1)/func.diff().subs(x, x1))\n",
    "x3 = x2 - (func.subs(x, x2)/func.diff().subs(x, x2))\n",
    "x4 = x3 - (func.subs(x, x3)/func.diff().subs(x, x3))\n",
    "\n",
    "print(x0, x1, N(x2, 4), N(x3, 4), N(x4, 4))\n",
    "\n",
    "#Или\n",
    "\n",
    "def func(x):\n",
    "    return x**3 - 72*x - 220\n",
    "np.round(newton(func=func, x0=x0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0554c626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2 0.734328358208955 0.529 0.525 0.525 0.525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-3.85)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задание 3.7\n",
    "func = x**2 + 9*x - 5\n",
    "x0 = 2.2\n",
    "\n",
    "x = symbols('x')\n",
    "x1 = x0 - (func.subs(x, x0)/func.diff().subs(x, x0))\n",
    "x2 = x1 - (func.subs(x, x1)/func.diff().subs(x, x1))\n",
    "x3 = x2 - (func.subs(x, x2)/func.diff().subs(x, x2))\n",
    "x4 = x3 - (func.subs(x, x3)/func.diff().subs(x, x3))\n",
    "x5 = x4 - (func.subs(x, x4)/func.diff().subs(x, x4))\n",
    "print(x0, x1, N(x2, 3), N(x3, 3), N(x4, 3), N(x5, 3)) #Ответ почему-то 0.52, \n",
    "#хотя при округлении должно быть 0.53, решение соответствует эталону\n",
    "\n",
    "# или\n",
    "def func(x):\n",
    "    return x**3 - 72*x - 220\n",
    "np.round(newton(func=func, x0=x0, tol=0.01), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6918d1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.167)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Задание 3.9\n",
    "def func(x):\n",
    "    return 8*x**3 - 2*x**2 - 450\n",
    "def funcdiff1(x):\n",
    "    return 24*x**2 - 4*x\n",
    "def funcdiff2(x):\n",
    "    return 48*x\n",
    "\n",
    "x0 = 42\n",
    "\n",
    "def newtons_method(f, fprime, x0, tol=0.0001):\n",
    "    iter_count = 0\n",
    "    x_curr = x0\n",
    "    f_val = f(x_curr)\n",
    "    while (abs(f_val) > tol):\n",
    "        f_val = f(x_curr)\n",
    "        f_prime_val = fprime(x_curr)\n",
    "        x_curr = x_curr - (f_val)/(f_prime_val)\n",
    "        iter_count += 1\n",
    "    return x_curr\n",
    "display(round(newtons_method(f=funcdiff1, fprime=funcdiff2, x0=x0, tol=0.0001), 3))\n",
    "\n",
    "np.round(newton(func=funcdiff1, fprime=funcdiff2, x0=x0, tol=0.0001), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de99609",
   "metadata": {},
   "source": [
    "### Юнит 4. Квазиньютоновские методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb20e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации: Optimization terminated successfully.\n",
      "Количество оценок: 3\n",
      "Решение: f([0. 0.]) = 0.00000\n",
      "--------------------\n",
      "Статус оптимизации CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Количество оценок: 3\n",
      "Решение: f([0. 0.]) = 0.00000\n"
     ]
    }
   ],
   "source": [
    "# определение функции\n",
    "def func(x):\n",
    "    return x[0]**2.0 + x[1]**2.0\n",
    "\n",
    "# Определение градиента\n",
    "def grad_func(x):\n",
    "    return np.array([x[0] * 2, x[1] * 2])\n",
    "\n",
    "x_0 = [1.0, 1.0]\n",
    "\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "\n",
    "print('Статус оптимизации: %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))\n",
    "print('-'*20)\n",
    "\n",
    "# определяем нашу функцию\n",
    "def func(x):\n",
    "    return x[0]**2.0 + x[1]**2.0\n",
    " \n",
    "#  определяем градиент функции\n",
    "def grad_func(x):\n",
    "    return np.array([x[0] * 2, x[1] * 2])\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = [1, 1]\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf4ee22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS-решение:\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: -1.0\n",
      "        x: [-4.000e+00  1.000e+00]\n",
      "      nit: 6\n",
      "      jac: [-1.776e-15  0.000e+00]\n",
      " hess_inv: [[ 6.667e-01  3.333e-01]\n",
      "            [ 3.333e-01  6.667e-01]]\n",
      "     nfev: 11\n",
      "     njev: 11\n",
      "--------------------\n",
      "L-BFGS-B решение:\n",
      "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: -0.9999999999999218\n",
      "        x: [-4.000e+00  1.000e+00]\n",
      "      nit: 4\n",
      "      jac: [ 2.900e-07  2.724e-07]\n",
      "     nfev: 9\n",
      "     njev: 9\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Задание 4.1\n",
    "def func(x):\n",
    "    return x[0]**2 - x[0]*x[1] + x[1]**2 + 9*x[0] - 6*x[1] + 20\n",
    "\n",
    "def grad_func(x):\n",
    "    return np.array([2*x[0] - x[1] + 9, -x[0] + 2*x[1] - 6])\n",
    "\n",
    "x_0 = [-400, -400]\n",
    "\n",
    "print('BFGS-решение:')\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "print(result)\n",
    "print('-'*20)\n",
    "\n",
    "print('L-BFGS-B решение:')\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "print(result)\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18d66a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталон:\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: -1.0\n",
      "        x: [-4.000e+00  1.000e+00]\n",
      "      nit: 6\n",
      "      jac: [-1.776e-15  0.000e+00]\n",
      " hess_inv: [[ 6.667e-01  3.333e-01]\n",
      "            [ 3.333e-01  6.667e-01]]\n",
      "     nfev: 11\n",
      "     njev: 11\n"
     ]
    }
   ],
   "source": [
    "print('Эталон:')\n",
    "def func(x):\n",
    "    return x[0] ** 2 - x[0] * x[1] + x[1] ** 2 + 9 * x[0] - 6 * x[1] + 20\n",
    "\n",
    "def grad_func(x):\n",
    "    return np.array([2 * x[0] - x[1] + 9, -x[0] + 2 * x[1] - 6])\n",
    "\n",
    "x_0 = [-400, -400]\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34a4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 42.75\n",
      "        x: [ 1.500e+00]\n",
      "      nit: 4\n",
      "      jac: [ 0.000e+00]\n",
      " hess_inv: [[ 5.000e-01]]\n",
      "     nfev: 5\n",
      "     njev: 5\n",
      "--------------------\n",
      "  message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 42.75\n",
      "        x: [ 1.500e+00]\n",
      "      nit: 2\n",
      "      jac: [ 0.000e+00]\n",
      "     nfev: 3\n",
      "     njev: 3\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "# Задание 4.4\n",
    "def func(x):\n",
    "    return x**2 - 3*x + 45\n",
    "\n",
    "def grad_func(x):\n",
    "    return 2*x - 3\n",
    "\n",
    "x_0 = 10\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "print(result)\n",
    "print('-'*20)\n",
    "\n",
    "#Задание 4.5\n",
    "def func(x):\n",
    "    return x**2 - 3*x + 45\n",
    "\n",
    "def grad_func(x):\n",
    "    return 2*x - 3\n",
    "\n",
    "x_0 = 10\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3b4cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFGS:\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 10.000000030008898\n",
      "        x: [ 1.316e-02  6.653e-14]\n",
      "      nit: 34\n",
      "      jac: [ 9.120e-06  7.984e-13]\n",
      " hess_inv: [[ 2.016e+02 -4.163e-09]\n",
      "            [-4.163e-09  7.317e-02]]\n",
      "     nfev: 37\n",
      "     njev: 37\n",
      "--------------------\n",
      "L-BFGS-B:\n",
      "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 10.00000000827103\n",
      "        x: [-9.527e-03 -2.322e-06]\n",
      "      nit: 37\n",
      "      jac: [-3.459e-06 -2.786e-05]\n",
      "     nfev: 40\n",
      "     njev: 40\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#Задание 4.7\n",
    "def func(x):\n",
    "    return x[0]**4 + 6*x[1]**2 + 10\n",
    "\n",
    "def grad_func(x):\n",
    "    return np.array([4*x[0]**3, 12*x[1]])\n",
    "\n",
    "x_0 = [100, 100]\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "print('BFGS:')\n",
    "print(result)\n",
    "print('-'*20)\n",
    "\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "print('L-BFGS-B:')\n",
    "print(result)\n",
    "print('-'*20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
