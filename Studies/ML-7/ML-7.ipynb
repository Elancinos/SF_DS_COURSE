{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ML-7. Оптимизация гиперпараметров модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импорты\n",
    "\n",
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from hyperopt import hp, fmin, STATUS_OK, tpe, Trials\n",
    "import optuna\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.506409</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209887</td>\n",
       "      <td>0.633426</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>0.376124</td>\n",
       "      <td>0.727093</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.651023</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151154</td>\n",
       "      <td>0.766505</td>\n",
       "      <td>0.170876</td>\n",
       "      <td>0.404546</td>\n",
       "      <td>0.787935</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.520564</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179949</td>\n",
       "      <td>0.768785</td>\n",
       "      <td>0.177341</td>\n",
       "      <td>0.471179</td>\n",
       "      <td>0.872241</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.765646</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536954</td>\n",
       "      <td>0.634936</td>\n",
       "      <td>0.342713</td>\n",
       "      <td>0.447162</td>\n",
       "      <td>0.672689</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.533952</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347966</td>\n",
       "      <td>0.757971</td>\n",
       "      <td>0.230667</td>\n",
       "      <td>0.272652</td>\n",
       "      <td>0.854116</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3751 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0            1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1            1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2            1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3            1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4            0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "...        ...       ...       ...   ...  ...       ...       ...       ...   \n",
       "3746         1  0.033300  0.506409  0.10  0.0  0.209887  0.633426  0.297659   \n",
       "3747         1  0.133333  0.651023  0.15  0.0  0.151154  0.766505  0.170876   \n",
       "3748         0  0.200000  0.520564  0.00  0.0  0.179949  0.768785  0.177341   \n",
       "3749         1  0.100000  0.765646  0.00  0.0  0.536954  0.634936  0.342713   \n",
       "3750         0  0.133333  0.533952  0.00  0.0  0.347966  0.757971  0.230667   \n",
       "\n",
       "            D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  \\\n",
       "0     0.585445  0.743663  ...      0      0      0      0      0      0   \n",
       "1     0.411754  0.836582  ...      1      1      1      1      0      1   \n",
       "2     0.517720  0.679051  ...      0      0      0      0      0      0   \n",
       "3     0.288764  0.805110  ...      0      0      0      0      0      0   \n",
       "4     0.303809  0.812646  ...      0      0      0      0      0      0   \n",
       "...        ...       ...  ...    ...    ...    ...    ...    ...    ...   \n",
       "3746  0.376124  0.727093  ...      0      0      0      0      0      0   \n",
       "3747  0.404546  0.787935  ...      0      0      1      0      1      0   \n",
       "3748  0.471179  0.872241  ...      0      0      0      0      0      0   \n",
       "3749  0.447162  0.672689  ...      0      0      0      0      0      0   \n",
       "3750  0.272652  0.854116  ...      0      0      0      0      0      0   \n",
       "\n",
       "      D1773  D1774  D1775  D1776  \n",
       "0         0      0      0      0  \n",
       "1         0      0      1      0  \n",
       "2         0      0      0      0  \n",
       "3         0      0      0      0  \n",
       "4         0      0      0      0  \n",
       "...     ...    ...    ...    ...  \n",
       "3746      0      0      0      0  \n",
       "3747      1      0      0      0  \n",
       "3748      0      0      0      0  \n",
       "3749      0      0      0      0  \n",
       "3750      0      0      0      0  \n",
       "\n",
       "[3751 rows x 1777 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/_train_sem09.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В датафрейме нет пропусков.\n"
     ]
    }
   ],
   "source": [
    "# Проверяем, есть ли пропуски в любом из столбцов\n",
    "has_missing = data.isnull().any().any()\n",
    "\n",
    "if has_missing:\n",
    "    print(\"В датафрейме есть пропуски.\")\n",
    "else:\n",
    "    print(\"В датафрейме нет пропусков.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Activity\n",
       "1    0.542255\n",
       "0    0.457745\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Смотрим распреление значений целевого признака\n",
    "data['Activity'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение почти ровное, но стратификация, думаю, не повредит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на выборки\n",
    "\n",
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия:\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.78\n",
      "--------------------------------------------------\n",
      "Случайный лес:\n",
      "accuracy на тестовом наборе: 0.81\n",
      "f1_score на тестовом наборе: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Построение изначальных базовых моделей\n",
    "print('Логистическая регрессия:')\n",
    "lr_base = linear_model.LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "lr_base.fit(X_train, y_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(lr_base.score(X_test, y_test)))\n",
    "y_test_pred = lr_base.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "print('Случайный лес:')\n",
    "rf_base = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_base.fit(X_train, y_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(rf_base.score(X_test, y_test)))\n",
    "y_test_pred = rf_base.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовые митрики есть. Приступаем к оптимизации гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "70 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.75033333 0.75066667        nan        nan 0.754      0.75366667\n",
      "        nan        nan 0.75       0.74833333        nan        nan\n",
      " 0.741      0.74133333        nan        nan 0.73666667 0.73666667\n",
      "        nan        nan 0.73366667 0.73366667        nan        nan\n",
      " 0.73466667 0.73333333        nan        nan 0.73333333 0.73333333\n",
      " 0.74933333 0.75066667 0.755      0.75166667 0.75333333 0.75333333\n",
      " 0.75266667 0.75266667 0.75033333 0.75       0.75233333 0.75233333\n",
      " 0.742      0.741      0.751      0.75033333 0.73566667 0.73666667\n",
      " 0.75033333 0.749      0.73333333 0.73466667 0.74733333 0.74766667\n",
      " 0.73333333 0.73366667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.23 s\n",
      "Wall time: 3min 29s\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.81\n",
      "Наилучшие значения гиперпараметров: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#Линейная регрессия\n",
    "param_grid_lr = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=1000 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid_lr, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time grid_search_lr.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_lr.score(X_test, y_test)))\n",
    "y_test_pred = grid_search_lr.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_lr.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.19 s\n",
      "Wall time: 1min 55s\n",
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.82\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 15, 'min_samples_leaf': 2, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "#Случайный лес\n",
    "param_grid_rf = {\n",
    "                'n_estimators': list(range(50, 200, 25)), #Количество деревьев\n",
    "                'min_samples_leaf': list(range(2, 10, 2)), # Количество листьев\n",
    "                'max_depth': list(range(10, 30, 5)) # Максимальная высота дерева\n",
    "               }\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "    ), \n",
    "    param_grid=param_grid_rf, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "\n",
    "%time grid_search_rf.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_rf.score(X_test, y_test)))\n",
    "y_test_pred = grid_search_rf.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_rf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "35 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.73333333 0.751      0.755      0.73333333        nan\n",
      " 0.74566667 0.75033333 0.747             nan 0.73833333 0.748\n",
      "        nan 0.73333333        nan 0.75266667        nan        nan\n",
      " 0.75366667 0.73633333]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 953 ms\n",
      "Wall time: 18.1 s\n",
      "f1_score на обучающем наборе: 0.80\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.81\n",
      "Наилучшие значения гиперпараметров: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Линейная регрессия\n",
    "\n",
    "random_search_lr = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42),\n",
    "    param_distributions=param_grid_lr,\n",
    "    cv=5,\n",
    "    n_iter=20,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time random_search_lr.fit(X_train, y_train) \n",
    "y_train_pred = random_search_lr.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_lr.score(X_test, y_test)))\n",
    "y_test_pred = random_search_lr.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_lr.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.59 s\n",
      "Wall time: 14.6 s\n",
      "f1_score на обучающем наборе: 0.99\n",
      "accuracy на тестовом наборе: 0.83\n",
      "f1_score на тестовом наборе: 0.84\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 150, 'min_samples_leaf': 2, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "#Случайный лес\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_grid_rf,\n",
    "    cv=5,\n",
    "    n_iter=20,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time random_search_rf.fit(X_train, y_train) \n",
    "y_train_pred = random_search_rf.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_rf.score(X_test, y_test)))\n",
    "y_test_pred = random_search_rf.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_rf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "# Параметры для линейной регрессии\n",
    "space_lr_1={\n",
    "    'penalty': hp.choice('penalty', ['l2']),\n",
    "    'solver': hp.choice('solver', ['lbfgs', 'sag']),\n",
    "    'C': hp.quniform('C', 0.01, 1, 0.1)\n",
    "}\n",
    "space_lr_2={\n",
    "    'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'solver': hp.choice('solver', ['saga', 'liblinear']),\n",
    "    'C': hp.quniform('C', 0.01, 1, 0.1)\n",
    "}\n",
    "\n",
    "#Параметры для случайного леса\n",
    "space_rf={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "      }\n",
    "\n",
    "random_state=42\n",
    "max_iter=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логистическая регрессия\n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty': str(params['penalty']), \n",
    "              'solver': str(params['solver']), \n",
    "              'C': float(params['C'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(**params, max_iter=max_iter, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return {'loss': -score, 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "\n",
    "# Случайный лес\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [09:08<00:00, 27.41s/trial, best loss: -0.7786349481373416]\n",
      "Наилучшие значения гиперпараметров {'C': 0.1, 'penalty': 0, 'solver': 0}\n",
      "CPU times: total: 5min 7s\n",
      "Wall time: 9min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Подбор параметров для логистической регрессии\n",
    "\n",
    "# Для первой подборки алгоритмов оптимизации\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best_lr_1=fmin(hyperopt_lr, # наша функция \n",
    "          space=space_lr_1, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best_lr_1))\n",
    "params_lr_1 = trials.best_trial['result']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [02:12<02:35, 11.93s/trial, best loss: -0.7781558796810103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [06:14<03:36, 27.07s/trial, best loss: -0.7781558796810103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [09:54<00:16, 16.26s/trial, best loss: -0.7816671635398847]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\telis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [12:10<00:00, 36.55s/trial, best loss: -0.7816671635398847]\n",
      "Наилучшие значения гиперпараметров {'C': 0.1, 'penalty': 0, 'solver': 1}\n",
      "CPU times: total: 5min 54s\n",
      "Wall time: 12min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Для второй подборки алгоритмов оптимизации\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best_lr_2=fmin(hyperopt_lr, # наша функция \n",
    "          space=space_lr_2, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best_lr_2))\n",
    "params_lr_2 = trials.best_trial['result']['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:38<00:00,  4.90s/trial, best loss: -0.81625044714172]  \n",
      "Наилучшие значения гиперпараметров для случайного леса {'max_depth': 18.0, 'min_samples_leaf': 2.0, 'n_estimators': 103.0}\n",
      "CPU times: total: 47.7 s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Подбор параметров для случайного леса\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best_rf=fmin(hyperopt_rf, # наша функция \n",
    "          space=space_rf, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров для случайного леса {}\".format(best_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.85\n",
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.79\n",
      "--------------------------------------------------\n",
      "f1_score на обучающем наборе: 0.80\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.81\n",
      "----------------------------------------------------------------------------------------------------\n",
      "f1_score на обучающем наборе: 0.99\n",
      "accuracy на тестовом наборе: 0.81\n",
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "#Логистическая регрессия 1\n",
    "model = linear_model.LogisticRegression(\n",
    "    random_state=random_state,\n",
    "    max_iter=max_iter,\n",
    "    penalty=str(params_lr_1['penalty']),\n",
    "    solver=str(params_lr_1['solver']),\n",
    "    C=float(params_lr_1['C'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "# Логистическая регрессия 2\n",
    "model = linear_model.LogisticRegression(\n",
    "    random_state=random_state,\n",
    "    max_iter=max_iter,\n",
    "    penalty=str(params_lr_2['penalty']),\n",
    "    solver=str(params_lr_2['solver']),\n",
    "    C=float(params_lr_2['C'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# Случайный лес\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best_rf['n_estimators']),\n",
    "    max_depth=int(best_rf['max_depth']),\n",
    "    min_samples_leaf=int(best_rf['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
