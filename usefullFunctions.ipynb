{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Полезные функции\n",
    "\n",
    "<center> Сюда буду добавлять полезные функции, которые могут пригодиться в будущем. В комментарии может быть код примера работы или дополнительные фичи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# функция, которая принимает количество кластеров для k-means и матрицу с признаками объектов и возвращает инерцию \n",
    "def get_inertia(cluster_num, X):\n",
    "# инициализируем алгоритм кластеризации\n",
    "    k_means =  KMeans(n_clusters=cluster_num, random_state=42)\n",
    "# запускаем алгоритм k-means\n",
    "    k_means.fit(X)\n",
    "# находим значение инерции\n",
    "    inertia = k_means.inertia_\n",
    "# возвращаем значение инерции\n",
    "    return inertia\n",
    "\n",
    "# # создаём пустой список для значений инерции\n",
    "# inertia = []\n",
    "# # итерируемся по разным размерам кластеров (от 1 до 9) и сохраняем значение инерции для каждого кластера\n",
    "# for cluster_num in range(1, 10):\n",
    "# # сохраняем значения\n",
    "#     inertia.append(get_inertia(cluster_num, X))\n",
    "\n",
    "# # визуализируем, как менялась инерция в зависимости от количества кластеров\n",
    "# # задаём названия осям x и y\n",
    "# plt.xlabel(\"cluster\", fontsize=12)\n",
    "# plt.ylabel(\"inertia\", fontsize=12)\n",
    "# # рисуем изменение инерции\n",
    "# plt.plot([i for i in range(1, 10)], inertia, 'xb-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем метрику силуэта\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# напишем функцию, как и при подсчете метода локтя\n",
    "def get_silhouette(cluster_num, X):\n",
    "    k_means =  KMeans(n_clusters=cluster_num, init='k-means++', n_init=10, random_state=42)\n",
    "    k_means.fit(X)\n",
    "# подсчитаем метрику силуэта, передав данные и то, к каким кластерам относятся объекты\n",
    "    silhouette = silhouette_score(X, k_means.predict(X))\n",
    "    return silhouette\n",
    "\n",
    "# # создадим пустой словарь, ключами будут инерция и количество кластеров\n",
    "# silhouette_res = {\"silhouette\": [], \"cluster\": []}\n",
    "\n",
    "# # выберем нужные данные \n",
    "# X = df[['Attack', 'Defense']]\n",
    "\n",
    "# for cluster_num in range(2, 10):\n",
    "#     silhouette_res[\"silhouette\"].append(get_silhouette(cluster_num, X))\n",
    "#     silhouette_res[\"cluster\"].append(cluster_num)\n",
    "    \n",
    "# # сохраним в датафрейм значение силуэта и количество кластеров\n",
    "# silhouette_df = pd.DataFrame(silhouette_res)\n",
    "\n",
    "# # установим стиль для визуализиции\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# # визуализируем зависимость значения инерции от количества кластеров\n",
    "# sns.lineplot(data=silhouette_df, x=\"cluster\", y=\"silhouette\", marker= \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Метод межквартильного размаха (метод Тьюки)\n",
    "#Модифицированная функция с настраиваемыми IQR, и проверкой на логарифмирование\n",
    "import numpy as np\n",
    "\n",
    "def outliers_iqr_mod(data, feature, log_scale=False, left=1.5, right=1.5):\n",
    "    \n",
    "    \"\"\"Функция для очистки дата-фрейма от выбросов по методу межквартильного размаха (метода Тьюки).\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): дата-фрейм с данными.\n",
    "        feature (pd.Series): признак (столбец) из дата-фрейма. \n",
    "        log_scale (bool, optional): Логарифмирование в процессе работы функции. Defaults to False.\n",
    "        left (float, optional): левый интервал, за пределами которого значения считаются выбросами. Defaults to 1.5.\n",
    "        right (float, optional): правый интервал, за пределами которого значения считаются выбросами. Defaults to 1.5.\n",
    "\n",
    "    Returns:\n",
    "        outliners (DataFrame): дата-фрейм со строками, которые функция посчитала выбросами.\n",
    "        cleaned (DataFtame): очищенный от выбросов дата-фрейм. \n",
    "    \"\"\"    \n",
    "    \n",
    "    if log_scale:\n",
    "        x = np.log(data[feature]+1)\n",
    "    else:\n",
    "        x = data[feature]\n",
    "    quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75)\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * left)\n",
    "    upper_bound = quartile_3 + (iqr * right)\n",
    "    outliners = data[(x < lower_bound)|(x > upper_bound)]\n",
    "    cleaned = data[(x >= lower_bound)&(x <= upper_bound)]\n",
    "    return outliners, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#метод z-отклонений (метод сигм)\n",
    "import numpy as np\n",
    "\n",
    "def outliers_z_score_mod(data, feature, log_scale=False,\n",
    "                         left=3, right=3):\n",
    "    \n",
    "    \"\"\"Функция для очистки дата-фрейма от выбросов по методу z-отклонений (методу сигм)\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): дата-фрейм с данными.\n",
    "        feature (pd.Series): признак (столбец) из дата-фрейма. \n",
    "        log_scale (bool, optional): Логарифмирование в процессе работы функции. Defaults to False.\n",
    "        left (float, optional): левый интервал, за пределами которого значения считаются выбросами. Defaults to 3.\n",
    "        right (float, optional): правый интервал, за пределами которого значения считаются выбросами. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        outliners (DataFrame): дата-фрейм со строками, которые функция посчитала выбросами.\n",
    "        cleaned (DataFtame): очищенный от выбросов дата-фрейм. \n",
    "    \"\"\"    \n",
    "    \n",
    "    if log_scale:\n",
    "        x = np.log(data[feature]+1)\n",
    "    else:\n",
    "        x = data[feature]\n",
    "    mu = x.mean()\n",
    "    sigma = x.std()\n",
    "    lower_bound = mu - left*sigma\n",
    "    upper_bound = mu + right*sigma\n",
    "    outliers = data[(x<lower_bound) | (x>upper_bound)]\n",
    "    cleaned = data[(x>lower_bound) & (x<upper_bound)]\n",
    "    return outliers, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_corr_heatmap(data, columns_list, title, fontsize=18, method='pearson'):\n",
    "    \n",
    "    \"\"\"Функция для построения тепловой карты корреляций столбцов дата-фрейма.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): дата-фрейм, по которому нужно построить тепловую карту.\n",
    "        columns_list (list): список столбцов, по которым нужно построить тепловую карту.\n",
    "        title (str): будущий заголовок тепловой карты.\n",
    "        fontsize (int): размер шрифта для заголовка. По умолчанию равен 18.\n",
    "        method (str, optional): метод корреляции признаков. По умолчанию используется корреляция Пирсона.\n",
    "    \"\"\"    \n",
    "    \n",
    "    fig_, ax_ = plt.subplots(figsize=(15, 15))\n",
    "    corr = data[columns_list].corr(method)\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    sns.heatmap(corr,\n",
    "                annot=True,\n",
    "                linewidths=0.1,\n",
    "                ax=ax_,\n",
    "                mask=mask,\n",
    "                cmap='viridis',\n",
    "                fmt='.1g')\n",
    "    ax_.set_title(title, fontsize=fontsize)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
